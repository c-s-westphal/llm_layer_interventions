# Configuration for Llama-3.1-8B temporal SAEs

# Model configuration
model_name: "meta-llama/Llama-3.1-8B"
sae_release: "temporal-sae-llama-3.1-8b"
hook: "resid_post"
layers: [15, 26]  # Only layers 15 and 26 available

# Intervention parameters
alpha: 2.0
alpha_sweep: [0, 0.5, 1, 2, 4]
live_percentile: 90

# Corpus configuration
corpus_name: "wikitext2"
max_passages: 200
test_passages: 1500
max_len: 256

# Feature selection
feature_source: "csv"
neuronpedia_token: null
top_k: 3

# Computation settings
device: "auto"
batch_size: 8  # Larger model, reduce batch size
seed: 1234

# Output configuration
output_dir: "outputs_llama"
save_snippets: true
snippet_window: 20
num_snippet_examples: 5
